{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# Customise our plotting settings\n",
    "rcParams['figure.figsize'] = 10, 5\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import resample\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data from csv files using the read_csv() fuction in the pandas library\n",
    "\n",
    "test= pd.read_csv('data/test_with_no_labels.csv')\n",
    "train= pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe will now be looking to China to make su...</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The scary, unimpeachable evidence that climate...</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid\n",
       "0  Europe will now be looking to China to make su...   169760\n",
       "1  Combine this with the polling of staffers re c...    35326\n",
       "2  The scary, unimpeachable evidence that climate...   224985\n",
       "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263\n",
       "4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 0, -1]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_values = list(train.sentiment.unique())\n",
    "sentiment_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.sentiment.value_counts().plot(kind='bar')\n",
    "plt.title('Number of observations per classes in train dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    8530\n",
       " 2    3640\n",
       " 0    2353\n",
       "-1    1296\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In text analytics, removing noise (i.e. unneccesary information) is a key part of getting the data into a usable format. Some techniques are standard, but your own data will require some creative thinking on your part.\n",
    "\n",
    "For the MBTI dataset we will be doing the following steps:\n",
    "\n",
    "removing the web-urls\n",
    "making everything lower case\n",
    "removing punctuation\n",
    "Regular expressions can be very useful for extracting information from text. If you feel brave, go teach yourself all about it... If not, just follow along. This next step effectively removes all websites and replaces them with the text 'web-url'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pattern_url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n",
    "#subs_url = r'url-web'\n",
    "#train['message'] = train['message'].replace(to_replace = pattern_url, value = subs_url, regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(df):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemm = WordNetLemmatizer()\n",
    "    Tokenized_Doc=[]\n",
    "    print(\"Preprocessing data.........\\n\")\n",
    "    for data in df['message']:\n",
    "        review = re.sub('[^a-zA-Z]', ' ', data)\n",
    "        url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "        review = url.sub(r'',review)\n",
    "        html=re.compile(r'<.*?>')\n",
    "        review = html.sub(r'',review)\n",
    "        emojis = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "        review = emojis.sub(r'',review)\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        tokens = tokenizer.tokenize(review)\n",
    "        gen_tweets = [lemm.lemmatize(token) for token in tokens if not token in stop_words]\n",
    "        Tokenized_Doc.append(gen_tweets)\n",
    "        df['tweet tokens'] = pd.Series(Tokenized_Doc)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data.........\n",
      "\n",
      "Preprocessing data.........\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cleaning the data\n",
    "train_df = data_cleaning(train)\n",
    "test_df = data_cleaning(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>no_handles</th>\n",
       "      <th>no_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "      <td>RT  Researchers say we have three years to act...</td>\n",
       "      <td>RT  Researchers say we have three years to act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "      <td>RT  It's 2016, and a racist, sexist, climate c...</td>\n",
       "      <td>RT  It's 2016, and a racist, sexist, climate c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221   \n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103   \n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562   \n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736   \n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954   \n",
       "\n",
       "                                          no_handles  \\\n",
       "0  PolySciMajor EPA chief doesn't think carbon di...   \n",
       "1  It's not like we lack evidence of anthropogeni...   \n",
       "2  RT  Researchers say we have three years to act...   \n",
       "3  #TodayinMaker# WIRED : 2016 was a pivotal year...   \n",
       "4  RT  It's 2016, and a racist, sexist, climate c...   \n",
       "\n",
       "                                             no_urls  \n",
       "0  PolySciMajor EPA chief doesn't think carbon di...  \n",
       "1  It's not like we lack evidence of anthropogeni...  \n",
       "2  RT  Researchers say we have three years to act...  \n",
       "3  #TodayinMaker# WIRED : 2016 was a pivotal year...  \n",
       "4  RT  It's 2016, and a racist, sexist, climate c...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_no_urls_handles = []\n",
    "\n",
    "for tweet in train['no_handles']:\n",
    "    tweet_no_urls_sub = re.sub('http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+', '', tweet)\n",
    "    tweets_no_urls_handles.append(tweet_no_urls_sub)\n",
    "    \n",
    "train['no_urls'] = tweets_no_urls_handles\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>no_handles</th>\n",
       "      <th>no_urls</th>\n",
       "      <th>no_capitals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>polyscimajor epa chief doesn't think carbon di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>it's not like we lack evidence of anthropogeni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "      <td>RT  Researchers say we have three years to act...</td>\n",
       "      <td>RT  Researchers say we have three years to act...</td>\n",
       "      <td>rt  researchers say we have three years to act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>#todayinmaker# wired : 2016 was a pivotal year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "      <td>RT  It's 2016, and a racist, sexist, climate c...</td>\n",
       "      <td>RT  It's 2016, and a racist, sexist, climate c...</td>\n",
       "      <td>rt  it's 2016, and a racist, sexist, climate c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221   \n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103   \n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562   \n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736   \n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954   \n",
       "\n",
       "                                          no_handles  \\\n",
       "0  PolySciMajor EPA chief doesn't think carbon di...   \n",
       "1  It's not like we lack evidence of anthropogeni...   \n",
       "2  RT  Researchers say we have three years to act...   \n",
       "3  #TodayinMaker# WIRED : 2016 was a pivotal year...   \n",
       "4  RT  It's 2016, and a racist, sexist, climate c...   \n",
       "\n",
       "                                             no_urls  \\\n",
       "0  PolySciMajor EPA chief doesn't think carbon di...   \n",
       "1  It's not like we lack evidence of anthropogeni...   \n",
       "2  RT  Researchers say we have three years to act...   \n",
       "3  #TodayinMaker# WIRED : 2016 was a pivotal year...   \n",
       "4  RT  It's 2016, and a racist, sexist, climate c...   \n",
       "\n",
       "                                         no_capitals  \n",
       "0  polyscimajor epa chief doesn't think carbon di...  \n",
       "1  it's not like we lack evidence of anthropogeni...  \n",
       "2  rt  researchers say we have three years to act...  \n",
       "3  #todayinmaker# wired : 2016 was a pivotal year...  \n",
       "4  rt  it's 2016, and a racist, sexist, climate c...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['no_capitals'] = train['no_urls'].str.lower()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>no_handles</th>\n",
       "      <th>no_urls</th>\n",
       "      <th>no_capitals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>polyscimajor epa chief doesn't think carbon di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>it's not like we lack evidence of anthropogeni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "      <td>RT  Researchers say we have three years to act...</td>\n",
       "      <td>RT  Researchers say we have three years to act...</td>\n",
       "      <td>rt  researchers say we have three years to act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>#todayinmaker# wired : 2016 was a pivotal year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "      <td>RT  It's 2016, and a racist, sexist, climate c...</td>\n",
       "      <td>RT  It's 2016, and a racist, sexist, climate c...</td>\n",
       "      <td>rt  it's 2016, and a racist, sexist, climate c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221   \n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103   \n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562   \n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736   \n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954   \n",
       "\n",
       "                                          no_handles  \\\n",
       "0  PolySciMajor EPA chief doesn't think carbon di...   \n",
       "1  It's not like we lack evidence of anthropogeni...   \n",
       "2  RT  Researchers say we have three years to act...   \n",
       "3  #TodayinMaker# WIRED : 2016 was a pivotal year...   \n",
       "4  RT  It's 2016, and a racist, sexist, climate c...   \n",
       "\n",
       "                                             no_urls  \\\n",
       "0  PolySciMajor EPA chief doesn't think carbon di...   \n",
       "1  It's not like we lack evidence of anthropogeni...   \n",
       "2  RT  Researchers say we have three years to act...   \n",
       "3  #TodayinMaker# WIRED : 2016 was a pivotal year...   \n",
       "4  RT  It's 2016, and a racist, sexist, climate c...   \n",
       "\n",
       "                                         no_capitals  \n",
       "0  polyscimajor epa chief doesn't think carbon di...  \n",
       "1  it's not like we lack evidence of anthropogeni...  \n",
       "2  rt  researchers say we have three years to act...  \n",
       "3  #todayinmaker# wired : 2016 was a pivotal year...  \n",
       "4  rt  it's 2016, and a racist, sexist, climate c...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['no_capitals'] = train['no_urls'].str.lower()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>no_capitals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "      <td>polyscimajor epa chief doesn't think carbon di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "      <td>it's not like we lack evidence of anthropogeni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "      <td>rt  researchers say we have three years to act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "      <td>#todayinmaker# wired : 2016 was a pivotal year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "      <td>rt  it's 2016, and a racist, sexist, climate c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221   \n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103   \n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562   \n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736   \n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954   \n",
       "\n",
       "                                         no_capitals  \n",
       "0  polyscimajor epa chief doesn't think carbon di...  \n",
       "1  it's not like we lack evidence of anthropogeni...  \n",
       "2  rt  researchers say we have three years to act...  \n",
       "3  #todayinmaker# wired : 2016 was a pivotal year...  \n",
       "4  rt  it's 2016, and a racist, sexist, climate c...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.drop(['no_handles', 'no_urls'], axis=1, inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "\n",
    "print(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text_data):\n",
    "    return ''.join([l for l in text_data if l not in punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>no_capitals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "      <td>rt  researchers say we have three years to act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "      <td>todayinmaker wired  2016 was a pivotal year in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "      <td>rt  its 2016 and a racist sexist climate chang...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221   \n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103   \n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562   \n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736   \n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954   \n",
       "\n",
       "                                         no_capitals  \n",
       "0  polyscimajor epa chief doesnt think carbon dio...  \n",
       "1  its not like we lack evidence of anthropogenic...  \n",
       "2  rt  researchers say we have three years to act...  \n",
       "3  todayinmaker wired  2016 was a pivotal year in...  \n",
       "4  rt  its 2016 and a racist sexist climate chang...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['no_capitals'] = train['no_capitals'].apply(remove_punctuation)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\phahlas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import TreebankWordTokenizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>no_capitals</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "      <td>[its, not, like, we, lack, evidence, of, anthr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "      <td>rt  researchers say we have three years to act...</td>\n",
       "      <td>[rt, researchers, say, we, have, three, years,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "      <td>todayinmaker wired  2016 was a pivotal year in...</td>\n",
       "      <td>[todayinmaker, wired, 2016, was, a, pivotal, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "      <td>rt  its 2016 and a racist sexist climate chang...</td>\n",
       "      <td>[rt, its, 2016, and, a, racist, sexist, climat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221   \n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103   \n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562   \n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736   \n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954   \n",
       "\n",
       "                                         no_capitals  \\\n",
       "0  polyscimajor epa chief doesnt think carbon dio...   \n",
       "1  its not like we lack evidence of anthropogenic...   \n",
       "2  rt  researchers say we have three years to act...   \n",
       "3  todayinmaker wired  2016 was a pivotal year in...   \n",
       "4  rt  its 2016 and a racist sexist climate chang...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...  \n",
       "1  [its, not, like, we, lack, evidence, of, anthr...  \n",
       "2  [rt, researchers, say, we, have, three, years,...  \n",
       "3  [todayinmaker, wired, 2016, was, a, pivotal, y...  \n",
       "4  [rt, its, 2016, and, a, racist, sexist, climat...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tokens'] = train['no_capitals'].apply(tokenizer.tokenize) # turns each column entry into a list of seperate words.\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "      <td>[its, not, like, we, lack, evidence, of, anthr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "      <td>[rt, researchers, say, we, have, three, years,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "      <td>[todayinmaker, wired, 2016, was, a, pivotal, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "      <td>[rt, its, 2016, and, a, racist, sexist, climat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221   \n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103   \n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562   \n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736   \n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954   \n",
       "\n",
       "                                              tokens  \n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...  \n",
       "1  [its, not, like, we, lack, evidence, of, anthr...  \n",
       "2  [rt, researchers, say, we, have, three, years,...  \n",
       "3  [todayinmaker, wired, 2016, was, a, pivotal, y...  \n",
       "4  [rt, its, 2016, and, a, racist, sexist, climat...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.drop(['no_capitals'], axis=1, inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_lemma(words, lemmatize):\n",
    "    return [lemmatizer.lemmatize(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [polyscimajor, epa, chief, doesnt, think, carb...\n",
       "1        [it, not, like, we, lack, evidence, of, anthro...\n",
       "2        [rt, researcher, say, we, have, three, year, t...\n",
       "3        [todayinmaker, wired, 2016, wa, a, pivotal, ye...\n",
       "4        [rt, it, 2016, and, a, racist, sexist, climate...\n",
       "                               ...                        \n",
       "15814    [rt, they, took, down, the, material, on, glob...\n",
       "15815    [rt, how, climate, change, could, be, breaking...\n",
       "15816    [notiven, rt, nytimesworld, what, doe, trump, ...\n",
       "15817    [rt, hey, liberal, the, climate, change, crap,...\n",
       "15818    [rt, climate, change, equation, in, 4, screens...\n",
       "Name: lemma, Length: 15819, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['lemma'] = train['tokens'].apply(tweet_lemma, args=(lemmatizer, ))\n",
    "train['lemma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "      <td>[its, not, like, we, lack, evidence, of, anthr...</td>\n",
       "      <td>[it, not, like, we, lack, evidence, of, anthro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "      <td>[rt, researchers, say, we, have, three, years,...</td>\n",
       "      <td>[rt, researcher, say, we, have, three, year, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "      <td>[todayinmaker, wired, 2016, was, a, pivotal, y...</td>\n",
       "      <td>[todayinmaker, wired, 2016, wa, a, pivotal, ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "      <td>[rt, its, 2016, and, a, racist, sexist, climat...</td>\n",
       "      <td>[rt, it, 2016, and, a, racist, sexist, climate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221   \n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103   \n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562   \n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736   \n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [its, not, like, we, lack, evidence, of, anthr...   \n",
       "2  [rt, researchers, say, we, have, three, years,...   \n",
       "3  [todayinmaker, wired, 2016, was, a, pivotal, y...   \n",
       "4  [rt, its, 2016, and, a, racist, sexist, climat...   \n",
       "\n",
       "                                               lemma  \n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...  \n",
       "1  [it, not, like, we, lack, evidence, of, anthro...  \n",
       "2  [rt, researcher, say, we, have, three, year, t...  \n",
       "3  [todayinmaker, wired, 2016, wa, a, pivotal, ye...  \n",
       "4  [rt, it, 2016, and, a, racist, sexist, climate...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "      <td>[it, not, like, we, lack, evidence, of, anthro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "      <td>[rt, researcher, say, we, have, three, year, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "      <td>[todayinmaker, wired, 2016, wa, a, pivotal, ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "      <td>[rt, it, 2016, and, a, racist, sexist, climate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221   \n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103   \n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562   \n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736   \n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954   \n",
       "\n",
       "                                               lemma  \n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...  \n",
       "1  [it, not, like, we, lack, evidence, of, anthro...  \n",
       "2  [rt, researcher, say, we, have, three, year, t...  \n",
       "3  [todayinmaker, wired, 2016, wa, a, pivotal, ye...  \n",
       "4  [rt, it, 2016, and, a, racist, sexist, climate...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.drop(['tokens'], axis=1, inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\phahlas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(lemmas):\n",
    "    return [l for l in lemmas if l not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>lemma</th>\n",
       "      <th>no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "      <td>[it, not, like, we, lack, evidence, of, anthro...</td>\n",
       "      <td>[like, lack, evidence, anthropogenic, global, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "      <td>[rt, researcher, say, we, have, three, year, t...</td>\n",
       "      <td>[rt, researcher, say, three, year, act, climat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "      <td>[todayinmaker, wired, 2016, wa, a, pivotal, ye...</td>\n",
       "      <td>[todayinmaker, wired, 2016, wa, pivotal, year,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "      <td>[rt, it, 2016, and, a, racist, sexist, climate...</td>\n",
       "      <td>[rt, 2016, racist, sexist, climate, change, de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221   \n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103   \n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562   \n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736   \n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954   \n",
       "\n",
       "                                               lemma  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...   \n",
       "1  [it, not, like, we, lack, evidence, of, anthro...   \n",
       "2  [rt, researcher, say, we, have, three, year, t...   \n",
       "3  [todayinmaker, wired, 2016, wa, a, pivotal, ye...   \n",
       "4  [rt, it, 2016, and, a, racist, sexist, climate...   \n",
       "\n",
       "                                        no_stopwords  \n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...  \n",
       "1  [like, lack, evidence, anthropogenic, global, ...  \n",
       "2  [rt, researcher, say, three, year, act, climat...  \n",
       "3  [todayinmaker, wired, 2016, wa, pivotal, year,...  \n",
       "4  [rt, 2016, racist, sexist, climate, change, de...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['no_stopwords'] = train['lemma'].apply(remove_stop_words)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "      <td>[like, lack, evidence, anthropogenic, global, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "      <td>[rt, researcher, say, three, year, act, climat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "      <td>[todayinmaker, wired, 2016, wa, pivotal, year,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "      <td>[rt, 2016, racist, sexist, climate, change, de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221   \n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103   \n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562   \n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736   \n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954   \n",
       "\n",
       "                                        no_stopwords  \n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...  \n",
       "1  [like, lack, evidence, anthropogenic, global, ...  \n",
       "2  [rt, researcher, say, three, year, act, climat...  \n",
       "3  [todayinmaker, wired, 2016, wa, pivotal, year,...  \n",
       "4  [rt, 2016, racist, sexist, climate, change, de...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.drop(['lemma'], axis=1, inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vic = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-a5fb67ef5053>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'no_stopwords'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence"
     ]
    }
   ],
   "source": [
    "X_count = vic.fit_transform(train['no_stopwords'].values.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15819, 20)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amp',\n",
       " 'believe',\n",
       " 'believe climate',\n",
       " 'change url',\n",
       " 'doesn',\n",
       " 'epa',\n",
       " 'global',\n",
       " 'global warming',\n",
       " 'going',\n",
       " 'just',\n",
       " 'people',\n",
       " 'real',\n",
       " 'trump',\n",
       " 'url web',\n",
       " 'url web',\n",
       " 'warming',\n",
       " 'web',\n",
       " 'web url',\n",
       " 'web',\n",
       " 'world']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vic.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.59735908, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.55091656, 0.60907737, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_count.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amp</th>\n",
       "      <th>believe</th>\n",
       "      <th>believe climate</th>\n",
       "      <th>change url</th>\n",
       "      <th>doesn</th>\n",
       "      <th>epa</th>\n",
       "      <th>global</th>\n",
       "      <th>global warming</th>\n",
       "      <th>going</th>\n",
       "      <th>just</th>\n",
       "      <th>people</th>\n",
       "      <th>real</th>\n",
       "      <th>trump</th>\n",
       "      <th>url web</th>\n",
       "      <th>url web</th>\n",
       "      <th>warming</th>\n",
       "      <th>web</th>\n",
       "      <th>web url</th>\n",
       "      <th>web</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.518934</td>\n",
       "      <td>0.561267</td>\n",
       "      <td>0.318736</td>\n",
       "      <td>0.328246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.327121</td>\n",
       "      <td>0.222826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.566696</td>\n",
       "      <td>0.583603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.581604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.567188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.566975</td>\n",
       "      <td>0.597359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.782716</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.440171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.440006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15814</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.566696</td>\n",
       "      <td>0.583603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.581604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15815</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.706974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15816</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550917</td>\n",
       "      <td>0.609077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.438714</td>\n",
       "      <td>0.257969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15817</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15818</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.706974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15819 rows  20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       amp   believe  believe climate  change url     doesn       epa  \\\n",
       "0      0.0  0.000000         0.000000    0.000000  0.518934  0.561267   \n",
       "1      0.0  0.000000         0.000000    0.000000  0.000000  0.000000   \n",
       "2      0.0  0.000000         0.000000    0.000000  0.000000  0.000000   \n",
       "3      0.0  0.000000         0.000000    0.782716  0.000000  0.000000   \n",
       "4      0.0  0.000000         0.000000    0.000000  0.000000  0.000000   \n",
       "...    ...       ...              ...         ...       ...       ...   \n",
       "15814  0.0  0.000000         0.000000    0.000000  0.000000  0.000000   \n",
       "15815  0.0  0.000000         0.000000    0.000000  0.000000  0.000000   \n",
       "15816  0.0  0.550917         0.609077    0.000000  0.000000  0.000000   \n",
       "15817  0.0  0.000000         0.000000    0.000000  0.000000  0.000000   \n",
       "15818  0.0  0.000000         0.000000    0.000000  0.000000  0.000000   \n",
       "\n",
       "         global  global warming  going  just  people  real     trump  \\\n",
       "0      0.318736        0.328246    0.0   0.0     0.0   0.0  0.000000   \n",
       "1      0.566696        0.583603    0.0   0.0     0.0   0.0  0.000000   \n",
       "2      0.000000        0.000000    0.0   0.0     0.0   0.0  0.000000   \n",
       "3      0.000000        0.000000    0.0   0.0     0.0   0.0  0.000000   \n",
       "4      0.000000        0.000000    0.0   0.0     0.0   0.0  0.000000   \n",
       "...         ...             ...    ...   ...     ...   ...       ...   \n",
       "15814  0.566696        0.583603    0.0   0.0     0.0   0.0  0.000000   \n",
       "15815  0.000000        0.000000    0.0   0.0     0.0   0.0  0.000000   \n",
       "15816  0.000000        0.000000    0.0   0.0     0.0   0.0  0.438714   \n",
       "15817  0.000000        0.000000    0.0   0.0     0.0   0.0  0.000000   \n",
       "15818  0.000000        0.000000    0.0   0.0     0.0   0.0  0.000000   \n",
       "\n",
       "        url web  url web   warming       web   web url  web  world  \n",
       "0      0.222910       0.0  0.327121  0.222826  0.000000   0.0    0.0  \n",
       "1      0.000000       0.0  0.581604  0.000000  0.000000   0.0    0.0  \n",
       "2      0.567188       0.0  0.000000  0.566975  0.597359   0.0    0.0  \n",
       "3      0.440171       0.0  0.000000  0.440006  0.000000   0.0    0.0  \n",
       "4      0.000000       0.0  0.000000  0.000000  0.000000   0.0    0.0  \n",
       "...         ...       ...       ...       ...       ...   ...    ...  \n",
       "15814  0.000000       0.0  0.581604  0.000000  0.000000   0.0    0.0  \n",
       "15815  0.707240       0.0  0.000000  0.706974  0.000000   0.0    0.0  \n",
       "15816  0.257969       0.0  0.000000  0.257872  0.000000   0.0    0.0  \n",
       "15817  0.000000       0.0  0.000000  0.000000  0.000000   0.0    0.0  \n",
       "15818  0.707240       0.0  0.000000  0.706974  0.000000   0.0    0.0  \n",
       "\n",
       "[15819 rows x 20 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_count.toarray(),columns=vic.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_count.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "# Fit label encoder and return encoded labels\n",
    "y = le.fit_transform(train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 3, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb=MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, ..., 2, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 3, ..., 0, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual=np.array(y_test)\n",
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pred)):\n",
    "    if pred[i]==actual[i]:\n",
    "        count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1837"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3164"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5805941845764855"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1837/3164.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       246\n",
      "           1       0.33      0.28      0.30       455\n",
      "           2       0.63      0.82      0.71      1730\n",
      "           3       0.57      0.41      0.48       733\n",
      "\n",
      "    accuracy                           0.58      3164\n",
      "   macro avg       0.38      0.38      0.37      3164\n",
      "weighted avg       0.52      0.58      0.54      3164\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_count_t = vic.fit_transform(test['message'].values.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_t = mnb.predict(X_count_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'tweetid': test.tweetid,\n",
    "    'sentiment': y_pred_t\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
